{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7741c00-deb1-427c-8175-ed0e38a3c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81024/2461910642.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Tuple\n",
    "import pandas\n",
    "\n",
    "sys.path.append('/home/danillorp/√Årea de Trabalho/github/fema/src/')\n",
    "\n",
    "\n",
    "import fema_semi\n",
    "import fema_classifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a4a3157-c950-442e-bcf3-a3ca1012c940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment will run for  12\n"
     ]
    }
   ],
   "source": [
    "ml_datasets = ['arrhythmia','Titanic','bank-marketing','vehicle','adult','airlines','PhishingWebsites',\n",
    "               'kc1','pc1','cmc','mfeat-factors','KDDCup09_appetency']\n",
    "\n",
    "#'credit-g','SpeedDating','blood-transfusion-service-center','mnist_784', 'satellite','one-hundred-plants-texture','steel-plates-fault',\n",
    "#'kr-vs-kp',\n",
    "print('The experiment will run for ',len(ml_datasets))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336b399b-cb34-433b-8c99-f510328f8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(dataset_name:str, data_x:pandas.core.frame.DataFrame, data_y:pandas.core.series.Series, test_size:float):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=test_size)\n",
    "    uknw_x, test_x, uknw_y, test_y = train_test_split(test_x, test_y, test_size=(1-test_size))\n",
    "\n",
    "    print(dataset_name)\n",
    "    print('train_size',len(train_x),'classes:',set(train_y))\n",
    "    print('test_size',len(test_x),'classes:',set(test_y))\n",
    "    print('uknw_size',len(uknw_x),'classes:',set(uknw_y))\n",
    "\n",
    "    #train_y = train_y.to_numpy()\n",
    "    #test_y = test_y.to_numpy()\n",
    "    #uknw_y = uknw_y.to_numpy()\n",
    "\n",
    "    train_y = train_y[:,np.newaxis]\n",
    "    test_y = test_y[:,np.newaxis]\n",
    "    uknw_y = uknw_y[:,np.newaxis]\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    test_x = scaler.transform(test_x)\n",
    "    uknw_x = scaler.transform(uknw_x)\n",
    "\n",
    "    #print(type(train_y),train_y.shape,train_y[:,0])\n",
    "\n",
    "    model_fema_original = fema_classifier.FEMaClassifier(k=10,basis=fema_classifier.Basis.shepardBasis)\n",
    "    model_fema_original.fit(train_x,train_y)\n",
    "\n",
    "    pred, confidence_level = model_fema_original.predict(test_x,2)\n",
    "\n",
    "    cm_fema_original = confusion_matrix(test_y,pred)\n",
    "    bal_acc_original = balanced_accuracy_score(test_y, pred)\n",
    "    acc_original = accuracy_score(test_y, pred)\n",
    "\n",
    "    print(dataset_name,cm_fema_original, bal_acc_original, acc_original)\n",
    "\n",
    "    model_semi = fema_semi.FEMaSemiSupervisedClassifier(k=10,basis=fema_semi.Basis.shepardBasis)\n",
    "    model_semi.fit(train_x,train_y,uknw_x,2)\n",
    "    \n",
    "    pred, confidence_level = model_semi.predict(test_x,2)\n",
    "    \n",
    "    cm_fema_semi = confusion_matrix(test_y,pred)\n",
    "    bal_acc_semi = balanced_accuracy_score(test_y, pred)\n",
    "    acc_semi = accuracy_score(test_y, pred)\n",
    "    \n",
    "    \n",
    "    print(cm_fema_semi, bal_acc_semi, acc_semi)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c33632-6080-4e00-9c9d-cc1103ad2d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrhythmia (452, 206) (452,) <class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "age                 int64\n",
      "height              int64\n",
      "weight              int64\n",
      "QRSduration         int64\n",
      "PRinterval          int64\n",
      "                   ...   \n",
      "chV6_SPwaveAmp    float64\n",
      "chV6_PwaveAmp     float64\n",
      "chV6_TwaveAmp     float64\n",
      "chV6_QRSA         float64\n",
      "chV6_QRSTA        float64\n",
      "Length: 206, dtype: object\n",
      "arrhythmia\n",
      "train_size 361 classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "test_size 73 classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12}\n",
      "uknw_size 18 classes: {0, 3, 4, 5, 7}\n",
      "arrhythmia [[32  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [10  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2]] 0.21875 0.4931506849315068\n",
      "18 13\n",
      "[[32  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [10  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2]] 0.21875 0.4931506849315068\n",
      "Titanic (1309, 6) (1309,) <class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "pclass      int64\n",
      "age       float64\n",
      "sibsp       int64\n",
      "parch       int64\n",
      "fare      float64\n",
      "body      float64\n",
      "dtype: object\n",
      "Titanic\n",
      "train_size 1047 classes: {0, 1}\n",
      "test_size 210 classes: {0, 1}\n",
      "uknw_size 52 classes: {0, 1}\n",
      "Titanic [[124   0]\n",
      " [ 86   0]] 0.5 0.5904761904761905\n",
      "52 2\n",
      "[[124   0]\n",
      " [ 86   0]] 0.5 0.5904761904761905\n",
      "bank-marketing (45211, 7) (45211,) <class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "V1     int64\n",
      "V6     int64\n",
      "V10    int64\n",
      "V12    int64\n",
      "V13    int64\n",
      "V14    int64\n",
      "V15    int64\n",
      "dtype: object\n",
      "bank-marketing\n",
      "train_size 36168 classes: {0, 1}\n",
      "test_size 7235 classes: {0, 1}\n",
      "uknw_size 1808 classes: {0, 1}\n"
     ]
    }
   ],
   "source": [
    "for dataset in ml_datasets: \n",
    "    data = fetch_openml(dataset,version=1)\n",
    "    X, y = data['data'], data['target']\n",
    "\n",
    "    X = X.select_dtypes(include=np.number)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "    \n",
    "    print(dataset, X.shape, y.shape, type(X), type(y))\n",
    "    print(X.dtypes)\n",
    "    experiment(dataset_name=dataset, data_x=X, data_y=y, test_size=0.20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
