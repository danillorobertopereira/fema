{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7741c00-deb1-427c-8175-ed0e38a3c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Tuple\n",
    "import pandas\n",
    "\n",
    "sys.path.append('/home/danillorp/√Årea de Trabalho/github/fema/src/')\n",
    "\n",
    "\n",
    "import fema_semi\n",
    "import fema_classifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4a3157-c950-442e-bcf3-a3ca1012c940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment will run for  10\n"
     ]
    }
   ],
   "source": [
    "ml_datasets = ['credit-g','satellite', 'Titanic','vehicle','blood-transfusion-service-center','one-hundred-plants-texture','steel-plates-fault','kc1','pc1','cmc']\n",
    "\n",
    "#'credit-g','airlines','satellite',\n",
    "#'Titanic','vehicle','adult','SpeedDating','blood-transfusion-service-center','mnist_784','one-hundred-plants-texture','steel-plates-fault',\n",
    "#'kr-vs-kp','arrhythmia','bank-marketing','PhishingWebsites','kc1','pc1','cmc','mfeat-factors','KDDCup09_appetency'\n",
    "print('The experiment will run for ',len(ml_datasets))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336b399b-cb34-433b-8c99-f510328f8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(dataset_name:str, data_x:pandas.core.frame.DataFrame, data_y:pandas.core.series.Series, test_size:float, n_runs:int, DEBUG:bool=False):\n",
    "    for i in range(n_runs):\n",
    "        #split datasets\n",
    "        train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=test_size)\n",
    "        uknw_x, test_x, uknw_y, test_y = train_test_split(test_x, test_y, test_size=test_size)\n",
    "    \n",
    "        if DEBUG:\n",
    "            print('**********',dataset_name,'**********')\n",
    "            print('train_size',len(train_x),'classes:',set(train_y))\n",
    "            print('test_size',len(test_x),'classes:',set(test_y))\n",
    "            print('uknw_size',len(uknw_x),'classes:',set(uknw_y))\n",
    "    \n",
    "        #reorganize the arrays to be an input of FEMa library\n",
    "        train_y = train_y[:,np.newaxis]\n",
    "        test_y = test_y[:,np.newaxis]\n",
    "        uknw_y = uknw_y[:,np.newaxis]\n",
    "    \n",
    "        #Apply data scaling based on training data\n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        train_x = scaler.fit_transform(train_x)\n",
    "        test_x = scaler.transform(test_x)\n",
    "        uknw_x = scaler.transform(uknw_x)\n",
    "    \n",
    "        #Run the model without the SemiSupervised\n",
    "        model_fema_original = fema_classifier.FEMaClassifier(k=50,basis=fema_classifier.Basis.shepardBasis)\n",
    "        model_fema_original.fit(train_x,train_y)\n",
    "    \n",
    "        pred, confidence_level = model_fema_original.predict(test_x,2)\n",
    "    \n",
    "        cm_fema_original = confusion_matrix(test_y,pred)\n",
    "        bal_acc_original = balanced_accuracy_score(test_y, pred)\n",
    "        acc_original = accuracy_score(test_y, pred)\n",
    "    \n",
    "        #print the accuracy of original solution\n",
    "        if DEBUG:\n",
    "            print('**********',dataset_name,'**********',i)\n",
    "            print('********** original **********')\n",
    "            print(cm_fema_original) \n",
    "            print(bal_acc_original, acc_original)\n",
    "    \n",
    "    \n",
    "        #Run the Semi Supervised FEMa\n",
    "        model_semi = fema_semi.FEMaSemiSupervisedClassifier(k=50,basis=fema_semi.Basis.shepardBasis)\n",
    "        model_semi.fit(train_x,train_y,uknw_x,2)\n",
    "        \n",
    "        pred, confidence_level = model_semi.predict(test_x,2)\n",
    "        \n",
    "        cm_fema_semi = confusion_matrix(test_y,pred)\n",
    "        bal_acc_semi = balanced_accuracy_score(test_y, pred)\n",
    "        acc_semi = accuracy_score(test_y, pred)\n",
    "        \n",
    "        #print the accuracy of original solution\n",
    "        if DEBUG:\n",
    "            print('********** semi **********')\n",
    "            print(cm_fema_semi) \n",
    "            print(bal_acc_semi)\n",
    "            print(acc_semi)\n",
    "    \n",
    "        #Run the Semi Supervised FEMa with Play Probabilities\n",
    "        \"\"\"model_semi.playProbabilities()\n",
    "        pred, confidence_level = model_semi.predict(test_x,2)\n",
    "        \n",
    "        cm_fema_semi = confusion_matrix(test_y,pred)\n",
    "        bal_acc_semi = balanced_accuracy_score(test_y, pred)\n",
    "        acc_semi = accuracy_score(test_y, pred)\n",
    "        \n",
    "        #print the accuracy of original solution\n",
    "        if DEBUG:\n",
    "            print('********** play **********')\n",
    "            print(cm_fema_semi) \n",
    "            print(bal_acc_semi)\n",
    "            print(acc_semi)\n",
    "        \"\"\"\n",
    "        #Run the Semi Supervised FEMa with Round Probabilities\n",
    "        model_semi.roundProbabilities()\n",
    "        pred, confidence_level = model_semi.predict(test_x,2)\n",
    "        \n",
    "        cm_fema_semi = confusion_matrix(test_y,pred)\n",
    "        bal_acc_semi = balanced_accuracy_score(test_y, pred)\n",
    "        acc_semi = accuracy_score(test_y, pred)\n",
    "        \n",
    "        #print the accuracy of original solution\n",
    "        if DEBUG:\n",
    "            print('********** round **********')\n",
    "            print(cm_fema_semi) \n",
    "            print(bal_acc_semi)\n",
    "            print(acc_semi)\n",
    "\n",
    "        \n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c33632-6080-4e00-9c9d-cc1103ad2d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** credit-g **********\n",
      "train_size 500 classes: {0, 1}\n",
      "test_size 250 classes: {0, 1}\n",
      "uknw_size 250 classes: {0, 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** credit-g ********** 0\n",
      "********** original **********\n",
      "[[ 10  63]\n",
      " [ 11 166]]\n",
      "0.537419704357248 0.704\n",
      "250 2\n",
      "********** semi **********\n",
      "[[  7  66]\n",
      " [  7 170]]\n",
      "0.528171194180017\n",
      "0.708\n",
      "********** round **********\n",
      "[[  5  68]\n",
      " [  5 172]]\n",
      "0.520122281557155\n",
      "0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** satellite **********\n",
      "train_size 2550 classes: {0, 1}\n",
      "test_size 1275 classes: {0, 1}\n",
      "uknw_size 1275 classes: {0, 1}\n",
      "********** satellite ********** 0\n",
      "********** original **********\n",
      "[[   5   15]\n",
      " [   0 1255]]\n",
      "0.625 0.9882352941176471\n",
      "1275 2\n",
      "********** semi **********\n",
      "[[   7   13]\n",
      " [   0 1255]]\n",
      "0.675\n",
      "0.9898039215686274\n",
      "********** round **********\n",
      "[[   8   12]\n",
      " [   0 1255]]\n",
      "0.7\n",
      "0.9905882352941177\n",
      "********** Titanic **********\n",
      "train_size 654 classes: {0, 1}\n",
      "test_size 328 classes: {0, 1}\n",
      "uknw_size 327 classes: {0, 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Titanic ********** 0\n",
      "********** original **********\n",
      "[[200   0]\n",
      " [128   0]]\n",
      "0.5 0.6097560975609756\n",
      "327 2\n",
      "********** semi **********\n",
      "[[200   0]\n",
      " [128   0]]\n",
      "0.5\n",
      "0.6097560975609756\n",
      "********** round **********\n",
      "[[200   0]\n",
      " [128   0]]\n",
      "0.5\n",
      "0.6097560975609756\n",
      "********** vehicle **********\n",
      "train_size 423 classes: {0, 1, 2, 3}\n",
      "test_size 212 classes: {0, 1, 2, 3}\n",
      "uknw_size 211 classes: {0, 1, 2, 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** vehicle ********** 0\n",
      "********** original **********\n",
      "[[47  2  2  2]\n",
      " [ 3 19 25  7]\n",
      " [ 9 14 23  6]\n",
      " [ 4  0  0 49]]\n",
      "0.6513700747191313 0.6509433962264151\n",
      "211 4\n",
      "********** semi **********\n",
      "[[49  3  0  1]\n",
      " [ 3 18 26  7]\n",
      " [ 9 14 22  7]\n",
      " [ 3  0  0 50]]\n",
      "0.6560836961780359\n",
      "0.6556603773584906\n",
      "********** round **********\n",
      "[[49  2  1  1]\n",
      " [ 3 15 27  9]\n",
      " [11 11 23  7]\n",
      " [ 6  0  0 47]]\n",
      "0.6328515562006127\n",
      "0.6320754716981132\n",
      "********** blood-transfusion-service-center **********\n",
      "train_size 374 classes: {0, 1}\n",
      "test_size 187 classes: {0, 1}\n",
      "uknw_size 187 classes: {0, 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** blood-transfusion-service-center ********** 0\n",
      "********** original **********\n",
      "[[139   6]\n",
      " [ 35   7]]\n",
      "0.5626436781609195 0.7807486631016043\n",
      "187 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** semi **********\n",
      "[[141   4]\n",
      " [ 36   6]]\n",
      "0.5576354679802955\n",
      "0.786096256684492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** round **********\n",
      "[[142   3]\n",
      " [ 36   6]]\n",
      "0.5610837438423645\n",
      "0.7914438502673797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** one-hundred-plants-texture **********\n",
      "train_size 799 classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99}\n",
      "test_size 400 classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99}\n",
      "uknw_size 400 classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** one-hundred-plants-texture ********** 0\n",
      "********** original **********\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 5]]\n",
      "0.6501683501683503 0.625\n",
      "400 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** semi **********\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 4]]\n",
      "0.6548821548821548\n",
      "0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** round **********\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 4]]\n",
      "0.6647306397306396\n",
      "0.64\n",
      "********** steel-plates-fault **********\n",
      "train_size 970 classes: {0, 1}\n",
      "test_size 486 classes: {0, 1}\n",
      "uknw_size 485 classes: {0, 1}\n",
      "********** steel-plates-fault ********** 0\n",
      "********** original **********\n",
      "[[305   6]\n",
      " [  3 172]]\n",
      "0.9817822691777676 0.9814814814814815\n",
      "485 2\n",
      "********** semi **********\n",
      "[[304   7]\n",
      " [  5 170]]\n",
      "0.9744602664216813\n",
      "0.9753086419753086\n",
      "********** round **********\n",
      "[[305   6]\n",
      " [  3 172]]\n",
      "0.9817822691777676\n",
      "0.9814814814814815\n",
      "********** kc1 **********\n",
      "train_size 1054 classes: {0, 1}\n",
      "test_size 528 classes: {0, 1}\n",
      "uknw_size 527 classes: {0, 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** kc1 ********** 0\n",
      "********** original **********\n",
      "[[439   8]\n",
      " [ 69  12]]\n",
      "0.5651255282127765 0.8541666666666666\n",
      "527 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** semi **********\n",
      "[[442   5]\n",
      " [ 68  13]]\n",
      "0.574654072416936\n",
      "0.8617424242424242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** round **********\n",
      "[[438   9]\n",
      " [ 72   9]]\n",
      "0.5454884414615958\n",
      "0.8465909090909091\n",
      "********** pc1 **********\n",
      "train_size 554 classes: {0, 1}\n",
      "test_size 278 classes: {0, 1}\n",
      "uknw_size 277 classes: {0, 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** pc1 ********** 0\n",
      "********** original **********\n",
      "[[259   1]\n",
      " [ 16   2]]\n",
      "0.5536324786324787 0.9388489208633094\n",
      "277 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** semi **********\n",
      "[[260   0]\n",
      " [ 17   1]]\n",
      "0.5277777777777778\n",
      "0.9388489208633094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** round **********\n",
      "[[260   0]\n",
      " [ 18   0]]\n",
      "0.5\n",
      "0.935251798561151\n",
      "********** cmc **********\n",
      "train_size 736 classes: {0, 1, 2}\n",
      "test_size 369 classes: {0, 1, 2}\n",
      "uknw_size 368 classes: {0, 1, 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** cmc ********** 0\n",
      "********** original **********\n",
      "[[146   2   3]\n",
      " [ 90   5   1]\n",
      " [115   0   7]]\n",
      "0.35878259991073475 0.4281842818428184\n",
      "368 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** semi **********\n",
      "[[149   2   0]\n",
      " [ 96   0   0]\n",
      " [120   0   2]]\n",
      "0.33438280317012264\n",
      "0.4092140921409214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/√Årea de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** round **********\n",
      "[[149   2   0]\n",
      " [ 95   0   1]\n",
      " [120   0   2]]\n",
      "0.33438280317012264\n",
      "0.4092140921409214\n"
     ]
    }
   ],
   "source": [
    "for dataset in ml_datasets: \n",
    "    data = fetch_openml(dataset,version=1)\n",
    "    X, y = data['data'], data['target']\n",
    "\n",
    "    X = X.select_dtypes(include=np.number)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(dataset, X.shape, y.shape, type(X), type(y))\n",
    "        print(X.dtypes)\n",
    "    \n",
    "    experiment(dataset_name=dataset, data_x=X, data_y=y, test_size=0.50,n_runs=3,DEBUG=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
