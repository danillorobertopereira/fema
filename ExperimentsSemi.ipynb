{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7741c00-deb1-427c-8175-ed0e38a3c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101962/644247639.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Tuple\n",
    "import pandas\n",
    "\n",
    "sys.path.append('/home/danillorp/Área de Trabalho/github/fema/src/')\n",
    "\n",
    "\n",
    "import fema_semi\n",
    "import fema_classifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4a3157-c950-442e-bcf3-a3ca1012c940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment will run for  3\n"
     ]
    }
   ],
   "source": [
    "ml_datasets = ['credit-g','airlines','satellite']\n",
    "\n",
    "#'Titanic','vehicle','adult','SpeedDating','blood-transfusion-service-center','mnist_784','one-hundred-plants-texture','steel-plates-fault',\n",
    "#'kr-vs-kp','arrhythmia','bank-marketing','PhishingWebsites','kc1','pc1','cmc','mfeat-factors','KDDCup09_appetency'\n",
    "print('The experiment will run for ',len(ml_datasets))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336b399b-cb34-433b-8c99-f510328f8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(dataset_name:str, data_x:pandas.core.frame.DataFrame, data_y:pandas.core.series.Series, test_size:float, n_runs:int, DEBUG:bool=False):\n",
    "    for i in range(n_runs):\n",
    "        #split datasets\n",
    "        train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=test_size)\n",
    "        uknw_x, test_x, uknw_y, test_y = train_test_split(test_x, test_y, test_size=test_size)\n",
    "    \n",
    "        if DEBUG:\n",
    "            print('**********',dataset_name,'**********')\n",
    "            print('train_size',len(train_x),'classes:',set(train_y))\n",
    "            print('test_size',len(test_x),'classes:',set(test_y))\n",
    "            print('uknw_size',len(uknw_x),'classes:',set(uknw_y))\n",
    "    \n",
    "        #reorganize the arrays to be an input of FEMa library\n",
    "        train_y = train_y[:,np.newaxis]\n",
    "        test_y = test_y[:,np.newaxis]\n",
    "        uknw_y = uknw_y[:,np.newaxis]\n",
    "    \n",
    "        #Apply data scaling based on training data\n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        train_x = scaler.fit_transform(train_x)\n",
    "        test_x = scaler.transform(test_x)\n",
    "        uknw_x = scaler.transform(uknw_x)\n",
    "    \n",
    "        #Run the model without the SemiSupervised\n",
    "        model_fema_original = fema_classifier.FEMaClassifier(k=50,basis=fema_classifier.Basis.shepardBasis)\n",
    "        model_fema_original.fit(train_x,train_y)\n",
    "    \n",
    "        pred, confidence_level = model_fema_original.predict(test_x,4)\n",
    "    \n",
    "        cm_fema_original = confusion_matrix(test_y,pred)\n",
    "        bal_acc_original = balanced_accuracy_score(test_y, pred)\n",
    "        acc_original = accuracy_score(test_y, pred)\n",
    "    \n",
    "        #print the accuracy of original solution\n",
    "        if DEBUG:\n",
    "            print('**********',dataset_name,'**********',i)\n",
    "            print('********** original **********')\n",
    "            print(cm_fema_original) \n",
    "            print(bal_acc_original, acc_original)\n",
    "    \n",
    "    \n",
    "        #Run the Semi Supervised FEMa\n",
    "        model_semi = fema_semi.FEMaSemiSupervisedClassifier(k=50,basis=fema_semi.Basis.shepardBasis)\n",
    "        model_semi.fit(train_x,train_y,uknw_x,2)\n",
    "        \n",
    "        pred, confidence_level = model_semi.predict(test_x,4)\n",
    "        \n",
    "        cm_fema_semi = confusion_matrix(test_y,pred)\n",
    "        bal_acc_semi = balanced_accuracy_score(test_y, pred)\n",
    "        acc_semi = accuracy_score(test_y, pred)\n",
    "        \n",
    "        #print the accuracy of original solution\n",
    "        if DEBUG:\n",
    "            print('********** semi **********')\n",
    "            print(cm_fema_semi) \n",
    "            print(bal_acc_semi)\n",
    "            print(acc_semi)\n",
    "    \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c33632-6080-4e00-9c9d-cc1103ad2d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** credit-g **********\n",
      "train_size 100 classes: {0, 1}\n",
      "test_size 810 classes: {0, 1}\n",
      "uknw_size 90 classes: {0, 1}\n",
      "********** credit-g ********** 0\n",
      "********** original **********\n",
      "[[ 37 208]\n",
      " [ 72 493]]\n",
      "0.5117933899223406 0.654320987654321\n",
      "90 2\n",
      "********** semi **********\n",
      "[[ 21 224]\n",
      " [ 55 510]]\n",
      "0.49418457648546144\n",
      "0.6555555555555556\n",
      "********** airlines **********\n",
      "train_size 53938 classes: {0, 1}\n",
      "test_size 436901 classes: {0, 1}\n",
      "uknw_size 48544 classes: {0, 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danillorp/Área de Trabalho/github/fema/src/fem_basis.py:33: RuntimeWarning: divide by zero encountered in divide\n",
      "  dist = 1.0/(dist**z)\n",
      "/home/danillorp/Área de Trabalho/github/fema/src/fem_basis.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  weitghs = dist[mask]/sum(dist[mask]+0.0000000001)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dataset, X\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mtype\u001b[39m(X), \u001b[38;5;28mtype\u001b[39m(y))\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mn_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(dataset_name, data_x, data_y, test_size, n_runs, DEBUG)\u001b[0m\n\u001b[1;32m     26\u001b[0m model_fema_original \u001b[38;5;241m=\u001b[39m fema_classifier\u001b[38;5;241m.\u001b[39mFEMaClassifier(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,basis\u001b[38;5;241m=\u001b[39mfema_classifier\u001b[38;5;241m.\u001b[39mBasis\u001b[38;5;241m.\u001b[39mshepardBasis)\n\u001b[1;32m     27\u001b[0m model_fema_original\u001b[38;5;241m.\u001b[39mfit(train_x,train_y)\n\u001b[0;32m---> 29\u001b[0m pred, confidence_level \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fema_original\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m cm_fema_original \u001b[38;5;241m=\u001b[39m confusion_matrix(test_y,pred)\n\u001b[1;32m     32\u001b[0m bal_acc_original \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(test_y, pred)\n",
      "File \u001b[0;32m~/Área de Trabalho/github/fema/src/fema_classifier.py:85\u001b[0m, in \u001b[0;36mFEMaClassifier.predict\u001b[0;34m(self, test_x, *args)\u001b[0m\n\u001b[1;32m     82\u001b[0m confidence_level \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_test_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes))\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_test_samples):\n\u001b[0;32m---> 85\u001b[0m     confidence_level[i,:] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasis(train_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_x, train_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability_classes[c], test_one_sample\u001b[38;5;241m=\u001b[39mtest_x[i], k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk, z\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)]\n\u001b[1;32m     86\u001b[0m     labels[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(confidence_level[i,:])\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels, confidence_level\n",
      "File \u001b[0;32m~/Área de Trabalho/github/fema/src/fema_classifier.py:85\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m confidence_level \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_test_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes))\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_test_samples):\n\u001b[0;32m---> 85\u001b[0m     confidence_level[i,:] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability_classes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_one_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)]\n\u001b[1;32m     86\u001b[0m     labels[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(confidence_level[i,:])\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels, confidence_level\n",
      "File \u001b[0;32m~/Área de Trabalho/github/fema/src/fem_basis.py:24\u001b[0m, in \u001b[0;36mBasis.shepardBasis\u001b[0;34m(train_x, train_y, test_one_sample, k, z)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshepardBasis\u001b[39m(train_x:np\u001b[38;5;241m.\u001b[39marray, train_y:np\u001b[38;5;241m.\u001b[39marray, test_one_sample:np\u001b[38;5;241m.\u001b[39marray, k:\u001b[38;5;28mint\u001b[39m, z:\u001b[38;5;28mint\u001b[39m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the weigths of the interpolation considering the Shepard \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    basis and return the predicted value\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m        np.array: return the weigths of the training samples\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m---> 24\u001b[0m         [np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(train_x[i]\u001b[38;5;241m-\u001b[39mtest_one_sample) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_x))]\n\u001b[1;32m     25\u001b[0m         )\n\u001b[1;32m     27\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(train_x),dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Área de Trabalho/github/fema/src/fem_basis.py:24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshepardBasis\u001b[39m(train_x:np\u001b[38;5;241m.\u001b[39marray, train_y:np\u001b[38;5;241m.\u001b[39marray, test_one_sample:np\u001b[38;5;241m.\u001b[39marray, k:\u001b[38;5;28mint\u001b[39m, z:\u001b[38;5;28mint\u001b[39m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the weigths of the interpolation considering the Shepard \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    basis and return the predicted value\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m        np.array: return the weigths of the training samples\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m---> 24\u001b[0m         [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtest_one_sample\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_x))]\n\u001b[1;32m     25\u001b[0m         )\n\u001b[1;32m     27\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(train_x),dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataset in ml_datasets: \n",
    "    data = fetch_openml(dataset,version=1)\n",
    "    X, y = data['data'], data['target']\n",
    "\n",
    "    X = X.select_dtypes(include=np.number)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(dataset, X.shape, y.shape, type(X), type(y))\n",
    "        print(X.dtypes)\n",
    "    \n",
    "    experiment(dataset_name=dataset, data_x=X, data_y=y, test_size=0.90,n_runs=3,DEBUG=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
