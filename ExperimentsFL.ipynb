{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37feecf0-7a6e-4001-8df9-82e3629e0eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117772/311831510.py:14: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "from numpy.random.mtrand import random\n",
    "\n",
    "sys.path.append('/home/danillorp/√Årea de Trabalho/github/fema/src/')\n",
    "\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "from fem_basis import Basis \n",
    "\n",
    "import pandas\n",
    "import fema_classifier\n",
    "import fema_feature_learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "DEBUG = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be27e942-e042-441a-b148-51c03475b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment will run for  3  datasets\n"
     ]
    }
   ],
   "source": [
    "ml_datasets = ['vehicle','credit-g','satellite']\n",
    "\n",
    "#'airlines','adult','SpeedDating','blood-transfusion-service-center','mnist_784','one-hundred-plants-texture','steel-plates-fault',\n",
    "#'kr-vs-kp','arrhythmia','bank-marketing','PhishingWebsites','kc1','pc1','cmc','mfeat-factors','KDDCup09_appetency'\n",
    "print('The experiment will run for ',len(ml_datasets),' datasets')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9662792-39e9-4061-9cf5-a3a690182ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(dataset_name:str, data_x:pandas.core.frame.DataFrame, data_y:pandas.core.series.Series, test_size:float, n_runs:int, DEBUG:bool=False):\n",
    "    for i in range(n_runs):\n",
    "        #split datasets\n",
    "        train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=test_size)\n",
    "        eval_x, test_x, eval_y, test_y = train_test_split(test_x, test_y, test_size=test_size)\n",
    "\n",
    "    \n",
    "        if DEBUG:\n",
    "            print('**********',dataset_name,'**********')\n",
    "            print('train_size',len(train_x),'classes:',set(train_y))\n",
    "            print('test_size',len(test_x),'classes:',set(test_y))\n",
    "        \n",
    "        #reorganize the arrays to be an input of FEMa library\n",
    "        train_y = train_y[:,np.newaxis]\n",
    "        test_y = test_y[:,np.newaxis]\n",
    "        eval_y = eval_y[:,np.newaxis]\n",
    "        \n",
    "        #Apply data scaling based on training data\n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        train_x = scaler.fit_transform(train_x)\n",
    "        test_x = scaler.transform(test_x)\n",
    "        eval_x = scaler.transform(eval_x)\n",
    "        \n",
    "        #Run the model without the SemiSupervised\n",
    "        model_fl = fema_feature_learning.FEMaFeatureLearning(k=10,basis=fema_classifier.Basis.radialBasis)\n",
    "        features_weigths = model_fl.fit(train_x, train_y, eval_x, eval_y)\n",
    "\n",
    "\n",
    "        model_fema_original = fema_classifier.FEMaClassifier(k=10,basis=fema_classifier.Basis.radialBasis)\n",
    "        model_fema_original.fit(train_x,train_y)\n",
    "\n",
    "        pred, confidence_level = model_fema_original.predict(test_x,10)\n",
    "\n",
    "        cm_fema_original = confusion_matrix(test_y,pred)\n",
    "        bal_original = balanced_accuracy_score(test_y, pred)\n",
    "        acc_original = accuracy_score(test_y, pred)\n",
    "\n",
    "        features_qtd = train_x.shape[1]\n",
    "        for c in range(len(set(train_y[:,0]))):\n",
    "            train_x_cp = train_x.copy()\n",
    "            test_x_cp  = test_x.copy()\n",
    "            \n",
    "        \n",
    "            for f in range(features_qtd):\n",
    "                mask_inter = train_y[:,0] != c\n",
    "                mask_intra = train_y == c\n",
    "                \n",
    "                train_x_cp[:,f] =   (train_x_cp[:,f])*  abs(features_weigths[model_fl.INTER, c, f]/features_weigths[model_fl.INTRA, c, f])\n",
    "                test_x_cp[:,f] =    (test_x_cp[:,f]) * abs(features_weigths[model_fl.INTER, c, f]/features_weigths[model_fl.INTRA, c, f])\n",
    "                \n",
    "        \n",
    "        model_fema_adjusted = fema_classifier.FEMaClassifier(k=10,basis=fema_classifier.Basis.radialBasis)\n",
    "        model_fema_adjusted.fit(train_x_cp,train_y)\n",
    "    \n",
    "        pred, confidence_level = model_fema_adjusted.predict(test_x_cp,10)\n",
    "    \n",
    "        cm_fema_adj = confusion_matrix(test_y,pred)\n",
    "        bal_adj = balanced_accuracy_score(test_y, pred)\n",
    "        acc_adj = accuracy_score(test_y, pred)\n",
    "\n",
    "        print('********************',dataset_name,'********************')\n",
    "        print('CM Original:',cm_fema_original)\n",
    "        print('CM Adjusted:',cm_fema_adj)\n",
    "        \n",
    "        print('BalAcc Original:',bal_original)\n",
    "        print('BalAcc Adjusted:',bal_adj)\n",
    "\n",
    "        print('Acc Original:',acc_original)\n",
    "        print('Acc Adjusted:',acc_adj)\n",
    "\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a273bfc5-2305-4dbd-8f43-639880094168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** vehicle **********\n",
      "train_size 84 classes: {0, 1, 2, 3}\n",
      "test_size 686 classes: {0, 1, 2, 3}\n",
      "******************** vehicle ********************\n",
      "CM Original: [[175   4   3   3]\n",
      " [ 18  73  67  18]\n",
      " [ 22  63  70  16]\n",
      " [ 19  10   6 119]]\n",
      "CM Adjusted: [[179   1   0   5]\n",
      " [133  18  24   1]\n",
      " [112  25  31   3]\n",
      " [ 84   2   3  65]]\n",
      "BalAcc Original: 0.6357006677730361\n",
      "BalAcc Adjusted: 0.4183011916564548\n",
      "Acc Original: 0.6370262390670554\n",
      "Acc Adjusted: 0.4271137026239067\n",
      "********** credit-g **********\n",
      "train_size 100 classes: {0, 1}\n",
      "test_size 810 classes: {0, 1}\n",
      "******************** credit-g ********************\n",
      "CM Original: [[104 142]\n",
      " [148 416]]\n",
      "CM Adjusted: [[111 135]\n",
      " [160 404]]\n",
      "BalAcc Original: 0.580176440062273\n",
      "BalAcc Adjusted: 0.5837657844663553\n",
      "Acc Original: 0.6419753086419753\n",
      "Acc Adjusted: 0.6358024691358025\n",
      "********** satellite **********\n",
      "train_size 510 classes: {0, 1}\n",
      "test_size 4131 classes: {0, 1}\n",
      "******************** satellite ********************\n",
      "CM Original: [[  53    6]\n",
      " [ 297 3775]]\n",
      "CM Adjusted: [[  59    0]\n",
      " [1758 2314]]\n",
      "BalAcc Original: 0.9126839765575572\n",
      "BalAcc Adjusted: 0.7841355599214146\n",
      "Acc Original: 0.9266521423384169\n",
      "Acc Adjusted: 0.5744371822803195\n"
     ]
    }
   ],
   "source": [
    "for dataset in ml_datasets: \n",
    "    data = fetch_openml(dataset,version=1)\n",
    "    X, y = data['data'], data['target']\n",
    "\n",
    "    X = X.select_dtypes(include=np.number)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(dataset, X.shape, y.shape, type(X), type(y))\n",
    "        print(X.dtypes)\n",
    "    \n",
    "    experiment(dataset_name=dataset, data_x=X, data_y=y, test_size=0.90,n_runs=3,DEBUG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4758aa-8e40-4438-8f38-69941479aa81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
